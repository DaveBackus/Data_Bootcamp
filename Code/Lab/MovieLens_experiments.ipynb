{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens \n",
    "\n",
    "**[MovieLens](https://movielens.org/)** is an online movie rating and recommendation system created by the [GroupLens](http://grouplens.org/) lab in the CS department of the University of Minnesota.  What's useful for us is that they post [lots of data](http://grouplens.org/datasets/movielens/) online that we can use.  We'll look at what they call their \"latest\" \"small\" dataset, which is enough to give us a sense of what's there. Note specifically the license terms (roughly:  mention source, problems are your own). We got the idea from Wes McKinney's [pandas book](http://www.amazon.com/dp/1449319793/).\n",
    "\n",
    "There are two aspects of this that take some work.  The first is reading individual files from a zip posted on the internet. The easy way is to do this is manually -- download the file, unzip it, read it from your hard drive -- but we prefer automated to easy.  The second aspect is merging information from different files.  \n",
    "\n",
    "This IPython notebook was created by Dave Backus and Brian LeBlanc in Python 3.5 for the NYU Stern course [Data Bootcamp](http://databootcamp.nyuecon.com/).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version:  3.5.1 |Anaconda 4.0.0 (64-bit)| (default, Feb 16 2016, 09:49:46) [MSC v.1900 64 bit (AMD64)]\n",
      "Pandas version:  0.18.0\n",
      "Requests version:  2.9.1\n",
      "Today's date: 2016-04-20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd             # data package\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import sys                      # system module, used to get Python version \n",
    "import datetime as dt           # date tools, used to note current date  \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "print('\\nPython version: ', sys.version) \n",
    "print('Pandas version: ', pd.__version__)\n",
    "print('Requests version: ', requests.__version__)\n",
    "print(\"Today's date:\", dt.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input\n",
    "\n",
    "The data comes as a zip file that contains several csv's.  We get the details from the README inside.  (It's written in Markdown, so it's easier to read if we use a browser to format it.  Or we could cut and paste into a Markdown cell in an IPython notebook, which we do at the bottom of this notebook.)  \n",
    "\n",
    "The file descriptions are:  \n",
    "\n",
    "* `ratings.csv`:  each line is an individual film rating with the rater and movie id's and the rating.  Order:  `userId, movieId, rating, timestamp`. \n",
    "* `tags.csv`:  each line is a tag on a specific film.  Order:  `userId, movieId, tag, timestamp`. \n",
    "* `movies.csv`:  each line is a movie name, it's id, and its genre.  Order:  `movieId, title, genres`.  Multiple genres are separated by \"pipes\" `|`.   \n",
    "* `links.csv`:  each line contains the movie id and corresponding id's at [IMBd](http://www.imdb.com/) and [TMDb](https://www.themoviedb.org/).  \n",
    "\n",
    "The easy way to input this data is to download the zip file onto our computer, unzip it, and read the individual csv files using `read.csv()`.  But anyone can do it the easy way.  We're looking for an automated way, so that if we do this again, possibly with updated data, the whole process is in our code.  \n",
    "\n",
    "Automated data entry involves these steps: \n",
    "\n",
    "* Get the file.  This uses the [requests](http://docs.python-requests.org/) package, which handles internet files and comes pre-installed with Anaconda. This kind of thing was hidden behind the scenes in the Pandas `read_csv()` and `read_excel()` functions, but here we need to do it for ourselves. The package authors add:  \n",
    ">Recreational use of other HTTP libraries may result in dangerous side-effects, including: security vulnerabilities, verbose code, reinventing the wheel, constantly reading documentation, depression, headaches, or even death.\"\n",
    "* Convert to zip.   Requests simply loads whatever's at the given url. The [io](https://docs.python.org/3.5/library/io.html) module's `io.Bytes` reconstructs it as a file, here a zip file.  \n",
    "* Unzip the file.  We use the [zipfile](https://docs.python.org/3.5/library/zipfile.html) module, which is part of core Python, to extract the files inside.   \n",
    "* Read in the csv's.  We use `read_csv` as usual.  \n",
    "\n",
    "We found this [Stack Overflow exchange](http://stackoverflow.com/questions/23419322/download-a-zip-file-and-extract-it-in-memory-using-python3) helpful. \n",
    "\n",
    "**Digression.**  This is probably more than you want to know, but it's a reminder of what goes on behind the scenes when we apply `read_csv` to a url.  Here we grab whatever is at the url.  Then we get its contents, convert it to bytes, identify it as a zip file, and read its components using `read_csv`.  It's a lot easier when this happens automatically, but a reminder what's involved if we ever have to look into the details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'requests.models.Response'>\n",
      "Response .content: <class 'bytes'>\n",
      "Respnse headers:\n",
      "{'Date': 'Sun, 21 Feb 2016 01:44:25 GMT', 'Server': 'Apache/2.2.22 (Ubuntu)', 'Content-Length': '1040425', 'Accept-Ranges': 'bytes', 'Keep-Alive': 'timeout=5, max=100', 'ETag': '\"80552-fe029-5291222b37ae7\"', 'Connection': 'Keep-Alive', 'Content-Type': 'application/zip', 'Last-Modified': 'Mon, 11 Jan 2016 17:19:11 GMT'}\n"
     ]
    }
   ],
   "source": [
    "# get \"response\" from url \n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "r = requests.get(url) \n",
    "\n",
    "print('Response type:', type(r))\n",
    "print('Response .content:', type(r.content)) \n",
    "print('Respnse headers:\\n', r.headers, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of zipfile object: <class 'zipfile.ZipFile'>\n"
     ]
    }
   ],
   "source": [
    "# convert bytes to zip file  \n",
    "mlz = zf.ZipFile(io.BytesIO(r.content))   \n",
    "print('Type of zipfile object:', type(mlz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ml-latest-small/',\n",
       " 'ml-latest-small/links.csv',\n",
       " 'ml-latest-small/movies.csv',\n",
       " 'ml-latest-small/ratings.csv',\n",
       " 'ml-latest-small/README.txt',\n",
       " 'ml-latest-small/tags.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's in the zip file?\n",
    "mlz.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract and read as csv's\n",
    "movies  = pd.read_csv(mlz.open(mlz.namelist()[2]))\n",
    "ratings = pd.read_csv(mlz.open(mlz.namelist()[3]))\n",
    "tags    = pd.read_csv(mlz.open(mlz.namelist()[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "Dimensions: (10329, 3)\n",
      "Variables: ['movieId', 'title', 'genres']\n",
      "Head:    movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "Dimensions: (105339, 4)\n",
      "Variables: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "Head:    userId  movieId  rating   timestamp\n",
      "0       1       16     4.0  1217897793\n",
      "1       1       24     1.5  1217895807\n",
      "2       1       32     4.0  1217896246\n",
      "3       1       47     4.0  1217896556\n",
      "4       1       50     4.0  1217896523\n",
      "\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "Dimensions: (6138, 4)\n",
      "Variables: ['userId', 'movieId', 'tag', 'timestamp']\n",
      "Head:    userId  movieId             tag   timestamp\n",
      "0      12       16        20060407  1144396544\n",
      "1      12       16  robert de niro  1144396554\n",
      "2      12       16        scorcese  1144396564\n",
      "3      17    64116    movie to see  1234720092\n",
      "4      21      260          action  1428011080\n"
     ]
    }
   ],
   "source": [
    "# what do we have? \n",
    "for df in [movies, ratings, tags]:\n",
    "    print('\\nType:', type(df))\n",
    "    print('Dimensions:', df.shape)\n",
    "    print('Variables:', list(df))\n",
    "    print('Head:', df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Toy Story's IMDb page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The README.txt from the MovieLens zip file\n",
    "\n",
    "---\n",
    "\n",
    "Summary\n",
    "=======\n",
    "\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 105339 ratings and 6138 tag applications across 10329 movies. These data were created by 668 users between April 03, 1996 and January 09, 2016. This dataset was generated on January 11, 2016.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in four files, `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`. More details about the contents and use of all these files follows.\n",
    "\n",
    "This is a *development* dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available *benchmark* datasets if that is your intent.\n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at <http://grouplens.org/datasets/>.\n",
    "\n",
    "\n",
    "Usage License\n",
    "=============\n",
    "\n",
    "Neither the University of Minnesota nor any of the researchers involved can guarantee the correctness of the data, its suitability for any particular purpose, or the validity of results based on the use of the data set. The data set may be used for any research purposes under the following conditions:\n",
    "\n",
    "* The user may not state or imply any endorsement from the University of Minnesota or the GroupLens Research Group.\n",
    "* The user must acknowledge the use of the data set in publications resulting from the use of the data set, and must send us an electronic or paper copy of those publications.\n",
    "* The user may redistribute the data set, including transformations, so long as it is distributed under these same license conditions.\n",
    "* The user may not use this information for any commercial or revenue-bearing purposes without first obtaining permission from a faculty member of the GroupLens Research Project at the University of Minnesota.\n",
    "* The executable software scripts are provided \"as is\" without warranty of any kind, either expressed or implied, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose. The entire risk as to the quality and performance of them is with you. Should the program prove defective, you assume the cost of all necessary servicing, repair or correction.\n",
    "\n",
    "In no event shall the University of Minnesota, its affiliates or employees be liable to you for any damages arising out of the use or inability to use these programs (including but not limited to loss of data or data being rendered inaccurate).\n",
    "\n",
    "If you have any further questions or comments, please email <grouplens-info@cs.umn.edu>\n",
    "\n",
    "\n",
    "Further Information About GroupLens\n",
    "===================================\n",
    "\n",
    "GroupLens is a research group in the Department of Computer Science and Engineering at the University of Minnesota. Since its inception in 1992, GroupLens's research projects have explored a variety of fields including:\n",
    "\n",
    "* recommender systems\n",
    "* online communities\n",
    "* mobile and ubiquitious technologies\n",
    "* digital libraries\n",
    "* local geographic information systems\n",
    "\n",
    "GroupLens Research operates a movie recommender based on collaborative filtering, MovieLens, which is the source of these data. We encourage you to visit <http://movielens.org> to try it out! If you have exciting ideas for experimental work to conduct on MovieLens, send us an email at <grouplens-info@cs.umn.edu> - we are always interested in working with external collaborators.\n",
    "\n",
    "\n",
    "Content and Use of Files\n",
    "========================\n",
    "\n",
    "Formatting and Encoding\n",
    "-----------------------\n",
    "\n",
    "The dataset files are written as [comma-separated values](http://en.wikipedia.org/wiki/Comma-separated_values) files with a single header row. Columns that contain commas (`,`) are escaped using double-quotes (`\"`). These files are encoded as UTF-8. If accented characters in movie titles or tag values (e.g. Mis√©rables, Les (1995)) display incorrectly, make sure that any program reading the data, such as a text editor, terminal, or script, is configured for UTF-8.\n",
    "\n",
    "User Ids\n",
    "--------\n",
    "\n",
    "MovieLens users were selected at random for inclusion. Their ids have been anonymized. User ids are consistent between `ratings.csv` and `tags.csv` (i.e., the same id refers to the same user across the two files).\n",
    "\n",
    "Movie Ids\n",
    "---------\n",
    "\n",
    "Only movies with at least one rating or tag are included in the dataset. These movie ids are consistent with those used on the MovieLens web site (e.g., id `1` corresponds to the URL <https://movielens.org/movies/1>). Movie ids are consistent between `ratings.csv`, `tags.csv`, `movies.csv`, and `links.csv` (i.e., the same id refers to the same movie across these four data files).\n",
    "\n",
    "\n",
    "Ratings Data File Structure (ratings.csv)\n",
    "-----------------------------------------\n",
    "\n",
    "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "    userId,movieId,rating,timestamp\n",
    "\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "\n",
    "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n",
    "Tags Data File Structure (tags.csv)\n",
    "-----------------------------------\n",
    "\n",
    "All tags are contained in the file `tags.csv`. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n",
    "\n",
    "    userId,movieId,tag,timestamp\n",
    "\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "\n",
    "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\n",
    "\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n",
    "Movies Data File Structure (movies.csv)\n",
    "---------------------------------------\n",
    "\n",
    "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId,title,genres\n",
    "\n",
    "Movie titles are entered manually or imported from <https://www.themoviedb.org/>, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles.\n",
    "\n",
    "Genres are a pipe-separated list, and are selected from the following:\n",
    "\n",
    "* Action\n",
    "* Adventure\n",
    "* Animation\n",
    "* Children's\n",
    "* Comedy\n",
    "* Crime\n",
    "* Documentary\n",
    "* Drama\n",
    "* Fantasy\n",
    "* Film-Noir\n",
    "* Horror\n",
    "* Musical\n",
    "* Mystery\n",
    "* Romance\n",
    "* Sci-Fi\n",
    "* Thriller\n",
    "* War\n",
    "* Western\n",
    "* (no genres listed)\n",
    "\n",
    "Links Data File Structure (links.csv)\n",
    "---------------------------------------\n",
    "\n",
    "Identifiers that can be used to link to other sources of movie data are contained in the file `links.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId,imdbId,tmdbId\n",
    "\n",
    "movieId is an identifier for movies used by <https://movielens.org>. E.g., the movie Toy Story has the link <https://movielens.org/movies/1>.\n",
    "\n",
    "imdbId is an identifier for movies used by <http://www.imdb.com>. E.g., the movie Toy Story has the link <http://www.imdb.com/title/tt0114709/>.\n",
    "\n",
    "tmdbId is an identifier for movies used by <https://www.themoviedb.org>. E.g., the movie Toy Story has the link <https://www.themoviedb.org/movie/862>.\n",
    "\n",
    "Use of the resources listed above is subject to the terms of each provider.\n",
    "\n",
    "Cross-Validation\n",
    "----------------\n",
    "\n",
    "Prior versions of the MovieLens dataset included either pre-computed cross-folds or scripts to perform this computation. We no longer bundle either of these features with the dataset, since most modern toolkits provide this as a built-in feature. If you wish to learn about standard approaches to cross-fold computation in the context of recommender systems evaluation, see [LensKit](http://lenskit.org) for tools, documentation, and open-source code examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
